{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c3399c4-809f-48eb-84b6-74ee19950573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform my imports\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig, AutoModelForCausalLM\n",
    "import heapq\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from typing import Optional, List\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM, BitsAndBytesConfig, TrainingArguments\n",
    "import json, csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig\n",
    "\n",
    "# Add the certs information\n",
    "sys.path.append(\"..\")\n",
    "from CeRTS_beam_multi import *\n",
    "from CeRTS_utils import *\n",
    "sys.path.remove(\"..\")\n",
    "\n",
    "# Add some fine-tuning specific functions\n",
    "from functions.generation_functions import *\n",
    "from functions.dataset_creation_functions import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466e27b2-565f-456f-84a8-3fa264e26b7b",
   "metadata": {},
   "source": [
    "# Data Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "484d93fc-b448-4b2e-9ea6-9d8933d9a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(\"clinical_data/validation.csv\")\n",
    "\n",
    "json_template = {\n",
    "    \"asthma\": \"yes|no\",\n",
    "    \"smoking\": \"yes|no\",\n",
    "    \"pneu\": \"yes|no\",            \n",
    "    \"common_cold\": \"yes|no\",\n",
    "    \"pain\": \"yes|no\",\n",
    "    \"fever\": \"high|low|no\",\n",
    "    \"antibiotics\": \"yes|no\"\n",
    "}\n",
    "features = json_template.keys()\n",
    "\n",
    "# add gold-standard output as text to df\n",
    "df_val = create_gold_standard_extractions(df_val, json_template)\n",
    "\n",
    "# Split into training and testing for temporary stuff \n",
    "df_val_train, df_val_test = train_test_split(df_val, test_size=0.2, random_state=42)\n",
    "df_val_train.reset_index(drop=True, inplace = True)\n",
    "df_val_test.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bae60f1-3d96-4561-bf77-fad0908b6566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"clinical_data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47f5fc7-00aa-4fa8-a860-54d91616c963",
   "metadata": {},
   "source": [
    "# Load in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b51855f-5fdd-4f7b-a882-af58c96ae2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7dcc5493c2a4d21b0bc45a2c3c96e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"models/llama-3.2-3b-instruct\"\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# load model (using float16 + device map for GPU efficiency)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5fd411-d8f3-4185-85ef-f2ef612a01d4",
   "metadata": {},
   "source": [
    "# Dataset in format for fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eafb78e-a1df-4a49-9ba6-94b447059b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Step\n",
    "train_data = format_for_standard_SFT(df_val_train, json_template)\n",
    "\n",
    "# # Put in List\n",
    "# train_data = [\n",
    "#     {\"messages\": conv} for conv in train_data   # conv is your list of role/content dicts\n",
    "# ]\n",
    "\n",
    "# Get in datasets\n",
    "train_data = Dataset.from_list(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b7f538c-6a43-4e87-9501-ce785f6ea21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'completion'],\n",
       "    num_rows: 800\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be7eb66-56d1-4c01-8259-32e556a4e180",
   "metadata": {},
   "source": [
    "# Define Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba495e4-3bd2-4bdf-8852-10f94489d5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9710767d037418b88be080ec6b46eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da71b49187f145ac8659015e3db2f7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=8,                        # low-rank dimension\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# ---- Step 4: Training arguments ----\n",
    "training_args = SFTConfig(\n",
    "    output_dir=f'{model_path}-SFT-val_test_10_15',\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=10,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    bf16=True,\n",
    "    completion_only_loss = True\n",
    ")\n",
    "\n",
    "# ---- Step 5: Trainer with PEFT/LoRA ----\n",
    "# updated_data = [\n",
    "#     {\"messages\": conv} for conv in train_data   # conv is your list of role/content dicts\n",
    "# ]\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    processing_class=tokenizer,\n",
    "    args=training_args,\n",
    "    peft_config=peft_config   # <<< LoRA here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ca30f-eef6-4587-a3e9-db43d32614ff",
   "metadata": {},
   "source": [
    "# Actually Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d43c2b99-12a3-45b4-ba07-40bbd7621d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 10:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.251700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.205800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.125900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.027600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.025400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.020900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.026100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.023900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LoRA adapter saved to models/llama-3.2-3b-instruct-SFT-val_test_10_15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('models/llama-3.2-3b-instruct-SFT-val_test_10_15-merged/tokenizer_config.json',\n",
       " 'models/llama-3.2-3b-instruct-SFT-val_test_10_15-merged/special_tokens_map.json',\n",
       " 'models/llama-3.2-3b-instruct-SFT-val_test_10_15-merged/chat_template.jinja',\n",
       " 'models/llama-3.2-3b-instruct-SFT-val_test_10_15-merged/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "trainer.train()\n",
    "\n",
    "# Then Save\n",
    "trainer.model.save_pretrained(training_args.output_dir)\n",
    "tokenizer.save_pretrained(training_args.output_dir)\n",
    "print(f\"✅ LoRA adapter saved to {training_args.output_dir}\")\n",
    "\n",
    "# Save merged Model (so don't have to marge and unload when using later)\n",
    "merged_model = trainer.model.merge_and_unload()\n",
    "final_model_dir = f\"{training_args.output_dir}-merged\"\n",
    "merged_model.save_pretrained(final_model_dir)\n",
    "tokenizer.save_pretrained(final_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8971c-8103-4500-bf0c-43181a85bc32",
   "metadata": {},
   "source": [
    "# Mess Around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf417b34-30d9-4ba2-a5d4-88be842f9ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Access preprocessed dataset\n",
    "# tokenized = trainer.train_dataset  # already tokenized internally\n",
    "\n",
    "# collator = trainer.data_collator\n",
    "sample = [trainer.train_dataset[1]]\n",
    "batch = collator(sample)\n",
    "\n",
    "\n",
    "# print(batch.keys())\n",
    "# print(batch[\"input_ids\"].shape, batch[\"labels\"].shape)\n",
    "\n",
    "# # Inspect where labels are masked\n",
    "tokens = tokenizer.convert_ids_to_tokens(batch[\"input_ids\"][0])\n",
    "# for t, l in zip(batch[\"input_ids\"][0], batch[\"labels\"][0].tolist()):\n",
    "#     print(f\"{tokenizer.decode(t):<25} {l}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d9eee23-f9e3-47ad-ab9a-3c2c640b21b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['messages', 'completion'],\n",
       "    num_rows: 800\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae9da7a-0a49-4362-bef6-8875e257ded9",
   "metadata": {},
   "source": [
    "# Now mess around with my data just to get used to transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dd51a8-6b69-4e26-9cfc-3438c8b1929b",
   "metadata": {},
   "source": [
    "### Load in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4828c33-e894-45e0-9839-9df4575a1528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0f0db5873041e6b48ef3087ebaf025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"models/llama-3.2-3b-instruct\"\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# load model (using float16 + device map for GPU efficiency)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    device_map=\"auto\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09033850-a3c7-4d95-90b0-472044ea5be3",
   "metadata": {},
   "source": [
    "### Now Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3de8f1bb-5485-47ef-afe3-ca4235281705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"asthma\": \"no\",\"smoking\": \"no\",\"pneu\": \"no\",\"common_cold\": \"yes\",\"pain\": \"no\",\"fever\": \"no\",\"antibiotics\": \"no\"}<|eot_id|>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 14\n",
    "\n",
    "# Model\n",
    "df_val.loc[n, 'advanced_text']\n",
    "prompt = gen_prompt_no_shot(df_val.loc[n, 'advanced_text'], features, json_template)\n",
    "\n",
    "# convert messages into a proper model input\n",
    "prompt = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# tokenize\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# generate response\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "# decode to string\n",
    "generated_tokens = outputs[0][inputs[\"input_ids\"].shape[-1]:]\n",
    "response = tokenizer.decode(generated_tokens, skip_special_tokens=False)\n",
    "\n",
    "# \n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c29ac70-2933-42e9-bf9d-9a75de4f1a0a",
   "metadata": {},
   "source": [
    "### Make Our Training Arguments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
